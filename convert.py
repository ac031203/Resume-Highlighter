# -*- coding: utf-8 -*-
"""ChadGPT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dSBoBKvsgQlPGFVL7VjuxVxowQ95UW4x
"""


import nltk
import spacy
from sentence_transformers import SentenceTransformer, util
import torch
import fitz

import PyPDF2
import re

def convert_pdf_to_text2(file_path):
    # Open the PDF file
    with fitz.open(file_path) as pdf_file:
        # Initialize an empty string to store the extracted text
        text = ''

        # Loop through each page in the PDF and extract the text
        for page in pdf_file:
            text += page.get_text()

    pattern = r'[•Ø§▪]'

    # Use the sub() function to replace the matched characters with a space
    cleaned_text = re.sub(pattern, ' ', text)

    return cleaned_text



import re

def split_into_sentences(text):
    # Split the text into sentences based on multiple consecutive white spaces
    sentences = re.split(r'\s{2,}|\n', text)

    # Remove leading and trailing whitespaces from each sentence
    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]

    return sentences


def normalize_scores(scores):
    min_score = min(score for sentence, score in scores)
    max_score = max(score for sentence, score in scores)
    normalized_scores = [(sentence, (score - min_score) / (max_score - min_score)) for sentence, score in scores]
    return normalized_scores

def evaluate(sentences,my_query):
    nlp = spacy.load("en_core_web_md")
    # Define the query and convert it to a spaCy Doc object
    query = my_query
    query_doc = nlp(query)

    # Calculate semantic similarity scores between the query and each sentence
    scores1 = []
    for sentence in sentences:
        sentence_doc = nlp(sentence)
        similarity_score = query_doc.similarity(sentence_doc)
        scores1.append((sentence, similarity_score))

    # Sort sentences by similarity score (optional)
    scores1.sort(key=lambda x: x[1], reverse=True)


    model = SentenceTransformer('all-MiniLM-L6-v2')
    # Define the query
    query = my_query

    # Compute embedding for the query and the sentences
    query_embedding = model.encode([query], convert_to_tensor=True)
    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)

    # Compute cosine-similarities
    cosine_scores = util.pytorch_cos_sim(query_embedding, sentence_embeddings)


    # Create a list of tuples containing sentence and cosine similarity score
    scores2 = [(sentences[i], cosine_scores[0][i].item()) for i in range(len(sentences))]

    # Sort scores in decreasing order
    scores2 = sorted(scores2, key=lambda x: x[1], reverse=True)


    model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    model = SentenceTransformer(model_name)

    # Query sentence
    query = my_query

    # Corpus sentences
    corpus = sentences

    # Encode the query and corpus sentences
    query_embedding = model.encode(query, convert_to_tensor=True)
    corpus_embeddings = model.encode(corpus, convert_to_tensor=True)

    # Calculate cosine similarity between query and corpus sentences
    cosine_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)


    scores3 = [(sentences[i], cosine_scores[0][i].item()) for i in range(len(sentences))]

    # Sort scores in decreasing order
    scores3 = sorted(scores3, key=lambda x: x[1], reverse=True)

    normalized_scores1 = normalize_scores(scores1)
    normalized_scores2 = normalize_scores(scores2)
    normalized_scores3 = normalize_scores(scores3)
    # Create a dictionary to store total weighted score for each sentence
    score_dict = {}
    for pairs, weight in zip([normalized_scores1, normalized_scores2, normalized_scores3], [0.2, 0.6, 0.2]):
        for sentence, score in pairs:
            if sentence not in score_dict:
                score_dict[sentence] = 0
            score_dict[sentence] += weight * score

    # Now score_dict contains the weighted average score for each sentence
    weighted_scores = list(score_dict.items())

    # Sort scores in decreasing order
    weighted_scores.sort(key=lambda x: x[1], reverse=True)


    return weighted_scores




# print(very_light_orange_terms)
def update_highlighting(file_path, output_path, very_light_orange_terms, very_light_yellow_terms, light_yellow_terms):
    doc = fitz.open(file_path)
    for page_num in range(len(doc)):
        page = doc[page_num]
        # First, clean all highlights to reapply them correctly
        page.clean_contents()


        # Very light yellow terms (Mildly Relevant)
        for term in very_light_yellow_terms:
            for inst in page.search_for(term):
                page.draw_rect(inst, color=(1, 1, 0), fill=(1, 1, 0.9), width=1.5, overlay=False)

        # Light yellow for "microservices architecture using Node.js and Express" (Relevant)
        for term in light_yellow_terms:
          for inst in page.search_for(term):
              page.draw_rect(inst, color=(1, 1, 0), fill=(1, 1, 0.8), width=1.5, overlay=False)

        # Very light orange terms (Very relevant)
        for term in very_light_orange_terms:
            for inst in page.search_for(term):
                page.draw_rect(inst, color=(1, 0.647, 0), fill=(1, 0.9, 0.7), width=1.5, overlay=False)

    doc.save(output_path)


def myconvertfunc(file_path, my_query, output_pdf_path):
    text = convert_pdf_to_text2(file_path)

    # Split the text into sentences
    sentences = split_into_sentences(text)
    sentences = list(set(sentences))

    weighted_scores = evaluate(sentences, my_query)
    dates = evaluate(sentences, "date or range of dates")
    l = []
    for i in range(min(15, len(dates))):
        s = dates[i][0]
        if len(s) < 35:
            l.append(s)
    for el in weighted_scores:
        if el[0] in l:
            weighted_scores.remove(el)
    top_5_percent_index = int(len(weighted_scores) * 0.05)
    # Assign the sentences with top 5% scores to very_light_orange_terms
    very_light_orange_terms = [sentence for sentence, score in weighted_scores[:top_5_percent_index]]

    # Assign the sentences with next 5% scores to light_yellow_terms
    light_yellow_terms = [sentence for sentence, score in weighted_scores[top_5_percent_index: 2 * top_5_percent_index]]

    # Assign the sentences with next 5% scores to very_light_yellow_terms
    very_light_yellow_terms = [sentence for sentence, score in weighted_scores[2 * top_5_percent_index: 3 * top_5_percent_index]]

    # Assume `update_highlighting` is a function to update highlighting
    update_highlighting(file_path, output_pdf_path, very_light_orange_terms, very_light_yellow_terms, light_yellow_terms)



